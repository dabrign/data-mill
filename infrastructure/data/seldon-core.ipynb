{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seldon-core\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/36/17fec0705e5ee81233ea94b8ea58d6199439643745a658a65be041ed124b/seldon_core-0.2.5-py3-none-any.whl (48kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 508kB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from seldon-core) (1.13.3)\n",
      "Collecting flask-cors (from seldon-core)\n",
      "  Downloading https://files.pythonhosted.org/packages/65/cb/683f71ff8daa3aea0a5cbb276074de39f9ab66d3fbb8ad5efb5bb83e90d2/Flask_Cors-3.0.7-py2.py3-none-any.whl\n",
      "Collecting redis (from seldon-core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/00/5253aff5e747faf10d8ceb35fb5569b848cde2fdc13685d42fcf63118bbc/redis-3.0.1-py2.py3-none-any.whl (61kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 1.3MB/s \n",
      "\u001b[?25hCollecting tensorflow (from seldon-core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/cc/ca70b78087015d21c5f3f93694107f34ebccb3be9624385a911d4b52ecef/tensorflow-1.12.0-cp36-cp36m-manylinux1_x86_64.whl (83.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 83.1MB 321kB/s \n",
      "\u001b[?25hCollecting flask (from seldon-core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7f/e7/08578774ed4536d3242b14dacb4696386634607af824ea997202cd0edb4b/Flask-1.0.2-py2.py3-none-any.whl (91kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 1.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from seldon-core) (2.21.0)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.6/site-packages (from seldon-core) (3.6.1)\n",
      "Collecting grpcio (from seldon-core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/bb/701d879849c938028c09fdb5405dbde7c86644bbbb90098094002db23ded/grpcio-1.17.1-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.1MB 1.2MB/s \n",
      "\u001b[?25hCollecting flatbuffers (from seldon-core)\n",
      "  Downloading https://files.pythonhosted.org/packages/21/9a/b0f3302f994b58bc26ebcc39218c14e33d8fa1bd96b7ba709597aff7507c/flatbuffers-1.10-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tornado in /opt/conda/lib/python3.6/site-packages (from seldon-core) (5.1.1)\n",
      "Requirement already satisfied: Six in /opt/conda/lib/python3.6/site-packages (from flask-cors->seldon-core) (1.12.0)\n",
      "Collecting astor>=0.6.0 (from tensorflow->seldon-core)\n",
      "  Downloading https://files.pythonhosted.org/packages/35/6b/11530768cac581a12952a2aad00e1526b89d242d0b9f59534ef6e6a1752f/astor-0.7.1-py2.py3-none-any.whl\n",
      "Collecting absl-py>=0.1.6 (from tensorflow->seldon-core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/63/f505d2d4c21db849cf80bad517f0065a30be6b006b0a5637f1b95584a305/absl-py-0.6.1.tar.gz (94kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 1.4MB/s \n",
      "\u001b[?25hCollecting gast>=0.2.0 (from tensorflow->seldon-core)\n",
      "  Downloading https://files.pythonhosted.org/packages/5c/78/ff794fcae2ce8aa6323e789d1f8b3b7765f601e7702726f430e814822b96/gast-0.2.0.tar.gz\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorflow->seldon-core) (0.32.3)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow->seldon-core)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting tensorboard<1.13.0,>=1.12.0 (from tensorflow->seldon-core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/7e/528c868bb8a0542c8a5686ff3a08502d2691bd50499c6e55f8989fa8e5a0/tensorboard-1.12.1-py3-none-any.whl (3.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.1MB 1.6MB/s \n",
      "\u001b[?25hCollecting keras-applications>=1.0.6 (from tensorflow->seldon-core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c4/2ff40221029f7098d58f8d7fb99b97e8100f3293f9856f0fb5834bef100b/Keras_Applications-1.0.6-py2.py3-none-any.whl (44kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 1.4MB/s \n",
      "\u001b[?25hCollecting keras-preprocessing>=1.0.5 (from tensorflow->seldon-core)\n",
      "  Downloading https://files.pythonhosted.org/packages/fc/94/74e0fa783d3fc07e41715973435dd051ca89c550881b3454233c39c73e69/Keras_Preprocessing-1.0.5-py2.py3-none-any.whl\n",
      "Collecting click>=5.1 (from flask->seldon-core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/37/45185cb5abbc30d7257104c434fe0b07e5a195a6847506c074527aa599ec/Click-7.0-py2.py3-none-any.whl (81kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 1.3MB/s \n",
      "\u001b[?25hCollecting Werkzeug>=0.14 (from flask->seldon-core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/c4/12e3e56473e52375aa29c4764e70d1b8f3efa6682bef8d0aae04fe335243/Werkzeug-0.14.1-py2.py3-none-any.whl (322kB)\n",
      "\u001b[K    100% |████████████████████████████████| 327kB 1.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: Jinja2>=2.10 in /opt/conda/lib/python3.6/site-packages (from flask->seldon-core) (2.10)\n",
      "Collecting itsdangerous>=0.24 (from flask->seldon-core)\n",
      "  Downloading https://files.pythonhosted.org/packages/76/ae/44b03b253d6fade317f32c24d100b3b35c2239807046a4c953c7b89fa49e/itsdangerous-1.1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->seldon-core) (2018.11.29)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->seldon-core) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->seldon-core) (1.24.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->seldon-core) (3.0.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf->seldon-core) (40.6.3)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.13.0,>=1.12.0->tensorflow->seldon-core)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/6b/5600647404ba15545ec37d2f7f58844d690baf2f81f3a60b862e48f29287/Markdown-3.0.1-py2.py3-none-any.whl (89kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 785kB/s \n",
      "\u001b[?25hRequirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow->seldon-core) (2.7.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.6/site-packages (from Jinja2>=2.10->flask->seldon-core) (1.1.0)\n",
      "Building wheels for collected packages: absl-py, gast, termcolor\n",
      "  Running setup.py bdist_wheel for absl-py ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/18/ea/5e/e36e1b8739e78cd2eba0a08fdc602c2b16a4b263912af8cb64\n",
      "  Running setup.py bdist_wheel for gast ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/9a/1f/0e/3cde98113222b853e98fc0a8e9924480a3e25f1b4008cedb4f\n",
      "  Running setup.py bdist_wheel for termcolor ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "Successfully built absl-py gast termcolor\n",
      "Installing collected packages: click, Werkzeug, itsdangerous, flask, flask-cors, redis, grpcio, astor, absl-py, gast, termcolor, markdown, tensorboard, keras-applications, keras-preprocessing, tensorflow, flatbuffers, seldon-core\n",
      "Successfully installed Werkzeug-0.14.1 absl-py-0.6.1 astor-0.7.1 click-7.0 flask-1.0.2 flask-cors-3.0.7 flatbuffers-1.10 gast-0.2.0 grpcio-1.17.1 itsdangerous-1.1.0 keras-applications-1.0.6 keras-preprocessing-1.0.5 markdown-3.0.1 redis-3.0.1 seldon-core-0.2.5 tensorboard-1.12.1 tensorflow-1.12.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install seldon-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-92dbdb5064f0>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "0.956254545455\n",
      "Classification report for classifier RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      2720\n",
      "           1       0.98      0.98      0.98      3161\n",
      "           2       0.94      0.96      0.95      2775\n",
      "           3       0.94      0.93      0.93      2780\n",
      "           4       0.96      0.96      0.96      2659\n",
      "           5       0.94      0.94      0.94      2480\n",
      "           6       0.97      0.97      0.97      2720\n",
      "           7       0.97      0.96      0.96      2823\n",
      "           8       0.94      0.94      0.94      2691\n",
      "           9       0.94      0.93      0.93      2691\n",
      "\n",
      "   micro avg       0.96      0.96      0.96     27500\n",
      "   macro avg       0.96      0.96      0.96     27500\n",
      "weighted avg       0.96      0.96      0.96     27500\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[2678    1    6    3    1    3    9    0   19    0]\n",
      " [   0 3097   20   10    8    4    3    9    7    3]\n",
      " [  13    5 2672   13   15    6   10   19   17    5]\n",
      " [   4    5   53 2582    3   51    4   26   33   19]\n",
      " [   3    5    7    2 2555    1   19    2   16   49]\n",
      " [  16    4    3   58    5 2341   18    3   21   11]\n",
      " [  12    5    5    1   12   25 2649    0    9    2]\n",
      " [   8   10   29    4   16    0    0 2701    7   48]\n",
      " [   3   15   18   32   11   40   16    4 2517   35]\n",
      " [  12    5   15   45   49   11    4   21   24 2505]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sk.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")\n",
    "\n",
    "mnist_images = mnist.train.images\n",
    "mnist_labels = mnist.train.labels\n",
    " # To apply a classifier on this data, we need to flatten the image, to\n",
    "    # turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(mnist_images)\n",
    "data = mnist_images.reshape((n_samples, -1))\n",
    "targets = mnist_labels\n",
    "\n",
    "data,targets = shuffle(data,targets)\n",
    "classifier = RandomForestClassifier(n_estimators=30)\n",
    "\n",
    "# We learn the digits on the first half of the digits\n",
    "classifier.fit(data[:n_samples // 2], targets[:n_samples // 2])\n",
    "\n",
    "# Now predict the value of the digit on the second half:\n",
    "expected = targets[n_samples // 2:]\n",
    "test_data = data[n_samples // 2:]\n",
    "\n",
    "print(classifier.score(test_data, expected))\n",
    "\n",
    "predicted = classifier.predict(data[n_samples // 2:])\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "          % (classifier, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "\n",
    "joblib.dump(classifier, 'sk.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-01-02 00:04:33--  https://github.com/openshift/source-to-image/releases/download/v1.1.13/source-to-image-v1.1.13-b54d75d3-linux-amd64.tar.gz\n",
      "Resolving github.com (github.com)... 140.82.118.4, 140.82.118.3\n",
      "Connecting to github.com (github.com)|140.82.118.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/16323162/0732a680-fd49-11e8-9a64-27933fd9207f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190102%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190102T000433Z&X-Amz-Expires=300&X-Amz-Signature=2e4ba3e0d1ddeb5513e2cb315177b6d259e71d5fe5138aaa92489ef82b3a8ce1&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dsource-to-image-v1.1.13-b54d75d3-linux-amd64.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2019-01-02 00:04:34--  https://github-production-release-asset-2e65be.s3.amazonaws.com/16323162/0732a680-fd49-11e8-9a64-27933fd9207f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190102%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190102T000433Z&X-Amz-Expires=300&X-Amz-Signature=2e4ba3e0d1ddeb5513e2cb315177b6d259e71d5fe5138aaa92489ef82b3a8ce1&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dsource-to-image-v1.1.13-b54d75d3-linux-amd64.tar.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.136.107\n",
      "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.136.107|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2571946 (2.5M) [application/octet-stream]\n",
      "Saving to: ‘source-to-image-v1.1.13-b54d75d3-linux-amd64.tar.gz’\n",
      "\n",
      "source-to-image-v1. 100%[===================>]   2.45M  1.09MB/s    in 2.3s    \n",
      "\n",
      "2019-01-02 00:04:36 (1.09 MB/s) - ‘source-to-image-v1.1.13-b54d75d3-linux-amd64.tar.gz’ saved [2571946/2571946]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/openshift/source-to-image/releases/download/v1.1.13/source-to-image-v1.1.13-b54d75d3-linux-amd64.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\n",
      "./s2i\n",
      "./sti\n",
      "tar: .: Cannot utime: Operation not permitted\n",
      "tar: .: Cannot change mode to rwx------: Operation not permitted\n",
      "tar: Exiting with failure status due to previous errors\n"
     ]
    }
   ],
   "source": [
    "!tar -xvf source-to-image-v1.1.13-b54d75d3-linux-amd64.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FATAL: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\n"
     ]
    }
   ],
   "source": [
    "!./s2i build . seldonio/seldon-core-s2i-python3:0.4 sk-mnist:0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
